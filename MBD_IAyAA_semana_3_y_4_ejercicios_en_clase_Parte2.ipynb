{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d3f06d9",
   "metadata": {},
   "source": [
    "# **Maestría en Analítica de Negocios**\n",
    "## **Curso: Inteligencia Artificial y Aprendizaje Automático**\n",
    "### Tecnológico de Monterrey\n",
    "### Prof Luis Eduardo Falcón Morales\n",
    "\n",
    "### **Semanas 3 y 4 : Ejercicios en Clase - Caso Regresión**\n",
    "## **Importancia de Factores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d7d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c169009",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, cs = make_regression(n_samples=1000,  # Se generan \"n\" registros \n",
    "                       n_features=12,       # Cantidad de variables generar (factores o variables no necesariamente independientes entre ellas).\n",
    "                       n_informative=6,     # Cantidad de factores independientes que generarán el modelo lineal de salida.\n",
    "                       n_targets=1,         # Cantidad de variables dependientes de salida.\n",
    "                       bias=0.,             # Valor constante del modelo lineal.\n",
    "                       noise=1,             # Desviación estándar del ruido gaussiano aplicado a los datos.\n",
    "                       coef=True,           # Para obtener los coeficientes del modelo usado para generar los datos.\n",
    "                       random_state=7       # semilla\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6875fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Información de los datos generados:')\n",
    "print('Datos de entrada X:', X.shape)\n",
    "print('Variable de salida y:', y.shape)\n",
    "print('Coeficientes del modelo generado:\\n', cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc57715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Xvt, y_train, yvt = train_test_split(X, y, train_size=0.60, random_state=0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X, y, test_size=0.50, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db78efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = LinearRegression()\n",
    "\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "print('valor de R2-Train:', modelo.score(X_train, y_train))  # Regresa el coeficiente de determianción de la predicción.\n",
    "print('valor de R2-Validation:', modelo.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fee226",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Diferencia entre los coeficientes reales y predichos:', (np.abs(modelo.coef_ - cs).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500a1cb",
   "metadata": {},
   "source": [
    "Bastante aceptable la aproximación, es decir, generamos un modelo completamente lineal y este modelo lineal encontrado lo explica al 99.99% :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3940f91c",
   "metadata": {},
   "source": [
    "# **Importancia de los Factores del modelo de regresión lineal en base a la magnitud de sus Coeficientes**\n",
    "\n",
    "Lo que queremos es identificar las variables o factores de mayor importancia o impacto en el comportamiento de la variable de salida \"y\".\n",
    "\n",
    "Ya comentamos en un ejercicio previo que una manera de medir la importancia de cada factor es con la magnitud de su coeficiente... y vemos que precisamente los coeficiente con un valor relativamente diferente de 0, coinciden con las variables independientes que se generaron al inicio. \n",
    "\n",
    "Sin embargo, volvemos a recordar que este método no es en general del todo válido, sobre todo cuando pueda haber también algunas relaciones no lineales entre algunos factores. Pero como hemos comentado, como una primera aproximación y habiendo escalado todos los factores al inicio, esta técnica podría empezar a darnos una buena idea muy rápido de cómo está participando cada factor en las predicciones del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ae5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = modelo.coef_\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    " print('Factor: %0d, Coef-modelo: %.5f, Coef-verdadero: %s' % (i,v,cs[i]>0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3d7535",
   "metadata": {},
   "source": [
    "Podemos visualizarlos de manera gráfica, para identificarlos mejor, sobre todo cuando son muchos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c79707",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh([pd.DataFrame(X_train).columns[x] for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4037a67",
   "metadata": {},
   "source": [
    "Identifica muy bien los 6 factores independientes y podríamos resaltar los factores 6, 9 y 10 como los que están en principio explicando mejor la variabilidad de la salida \"y\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6090c2ec",
   "metadata": {},
   "source": [
    "# **Importancia de los Factores del modelo de regresión lineal en base a la técnica llamada Importancia de Permutaciones (Permutation Importance)**\n",
    "\n",
    "Este método funciona como sigue: una vez obtenido el modelo de regresión buscado, se calcula algún tipo de error en el cunjunto de entrenamiento o de validación. Generalmente conviene usar el conjunto de validación, para tener una mejor idea de cómo generalizará el modelo en sus predicciones.\n",
    "\n",
    "En cuanto al error a calcular, para el caso de un modelo de regresión lineal podría ser $R^2$, MSE, RMSE, MAE, MAPE, etc. Y en un problema de clasificación se podría usar la exactitud (accuracy), la precisión (precision), la exhaustividad (recall), f1-score, etc. La elección del error estará también asociada a qué se quiere dar mayor importancia en las inferencias, en dado caso.\n",
    "\n",
    "A continuación, se elige una columna (variable independiente o factor) al azar y se revuelven aleatoriamente todos sus elementos (matemáticamente a esta acción de revolverlos o intercambiarlos de lugar sin quitar o agregar elementos nuevos se le llama Permutación). Una vez revueltos se vuelve a calcular el error elegido y se mide qué tanto se afectó el desempeño del modelo, con respecto al calculado con todos los factores en orden. Mientras mayor sea el cambio de dicho error, mayor \"importancia\" o \"calificación\" se le asigna a dicho factor. Menor menor sea el impacto o afectación en el error inicial, menor la \"importancia\" de ese factor.\n",
    "\n",
    "Este proceso se repite varias veces, promediando y ponderando el impacto que cada factor tuvo en el total de permutaciones realizadas.\n",
    "\n",
    "Como podemos inferir de esta técnica, nos da una idea más robusta de la participación de cada variable, aunque nuevamente podrían existir dependencias entre algunos factores que no refleje exactamente la imprtancia asignada.\n",
    "\n",
    "Por otro lado, esta técnica puede aplicarse a cualquier modelo lineal o no lineal, como las redes neuronales que estudiaremos más adelante. Por lo que para un mismo problema se podría aplicar el mismo proceso con diferentes modelos y observar las coincidencias o diferencias entre los diferentes factores y sus impactos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c39a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6cd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c8b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resultados = permutation_importance(modelo, X_val, y_val, scoring='neg_mean_squared_error')\n",
    "\n",
    "importance = resultados.importances_mean\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    " print('Factor: %0d, Coef-modelo: %.5f, Coef-verdadero: %s' % (i,v,cs[i]>0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40babab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh([pd.DataFrame(X_train).columns[x] for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dedb8a5",
   "metadata": {},
   "source": [
    "Observa que la magnitud del impacto ahora se reslata más en las 3 o 4 de mayor magnitud y en este caso los factores 8 y 11, disminuyen bastante la calificación de su influencia en la variable de salida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6368106",
   "metadata": {},
   "source": [
    "# Select Factors from Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea69e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e780659",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f = 3\n",
    "\n",
    "# Indicamos el modelo que se usará para evaluar la importancia de los factores\n",
    "# y la cantidad de ellos que se desean extraer:\n",
    "fs = SelectFromModel(estimator=LinearRegression(), max_features=max_f)\n",
    "# ajustamos con  los datos de entrenamiento para determinar cuáles se consideran los más relevantes:\n",
    "fs.fit(X_train, np.ravel(y_train))\n",
    "# y ahora obtenemos los factores\n",
    "factor_select = fs.get_support()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d708c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_fs = pd.DataFrame(X_train)[pd.DataFrame(X_train).columns[factor_select]]\n",
    "Xval_fs = pd.DataFrame(X_val)[pd.DataFrame(X_val).columns[factor_select]]\n",
    "Xtest_fs = pd.DataFrame(X_test)[pd.DataFrame(X_test).columns[factor_select]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd921c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_fs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af71aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(Xtrain_fs, pd.DataFrame(y_train))\n",
    "\n",
    "# evaluate the model\n",
    "#ytrainhat = model.predict(Xtrain_fs)\n",
    "#yvalhat = model.predict(Xval_fs)\n",
    "#ytesthat = model.predict(Xtest_fs)\n",
    "\n",
    "# evaluate predictions\n",
    "R2train = model.score(Xtrain_fs, y_train)\n",
    "R2val = model.score(Xval_fs, y_val)\n",
    "R2test = model.score(Xtest_fs, y_test)\n",
    "\n",
    "print('R2-Train: %.2f' % (R2train*100))\n",
    "print('R2-Val: %.2f' % (R2val*100))\n",
    "print('R2-Test: %.2f' % (R2test*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fa6ce4",
   "metadata": {},
   "source": [
    "Bastante bien, con 4 factores se obtiene un 96.6% aprox del $R^2$ y usando solo los 3 factores de mayor impacto obtenemos un 85%, aprox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af6d635",
   "metadata": {},
   "source": [
    "# Correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e8713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = pd.concat([pd.DataFrame(y_train), pd.DataFrame(X_train)], axis=1).corr(numeric_only=True)\n",
    "f, ax = plt.subplots(figsize = (9,9))\n",
    "sns.heatmap(correlations, annot=True, cbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa0f7d7",
   "metadata": {},
   "source": [
    "Observa que las de mayor correlación con la variable de salida son nuevamente los mismos factores y con el mismo orden de importancia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3e274f",
   "metadata": {},
   "source": [
    "# Importancia de los factores mediante el Factor de Inflación de la Varianza\n",
    "\n",
    "# VIF (Variance Inflation Factor) o el problema de la multicolinealidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a835ced7",
   "metadata": {},
   "source": [
    "La multicolinealidad es un problema en modelos como la regresión lineal, el hace que los coeficientes obtenidos se comporten de manera inestable, lo cual se refleja en coeficientes de magnitud muy grande (aún cuando se hayan escalado los factores de entrada). \n",
    "\n",
    "De manera simple, podemos decir que la multicolinealidad refleja la dependencia que puedan tener entre sí algunas de las variables independientes de un problema, afectando en la interpretación y efecto que pueda tener cada una de manera individual en la variable de salida.\n",
    "\n",
    "Matemáticamente se define el Factor de Inflación de la Varianza, VIF, para cada varaible o factor $k$ de la manera siguiente:\n",
    "\n",
    "###     $VIF_k = \\frac{1}{1-R^2_k}$\n",
    "\n",
    "donde $R^2_k$ es el coeficiente de correlación del factor $k$ con respecto al resto de las demás variables independientes.\n",
    "\n",
    "Recordemos que mientras mayor sea la relación lineal de una variable de salida con respecto a sus variables de entrada, más cercano el valor de $R^2$ a 1. Y mientras menos exista esta dependencia lineal, más cercano a 0. De aquí que, de manera general, podamos decir que cuando el valor de $VIF_k$ \"crezca mucho\" en alguno de los factores $k$, entonces dicho factor $k$ tiene una dependencia muy alta con respecto a uno o más del resto de los factores. Y esto puede utilizarse en ocasiones para eliminir dicho factor del modelo. \n",
    "\n",
    "Decir que el valor de $VIF_k$ es muy grande para algún factor es relativo y depende en general del problema en cuestión, sin embargo es común utilizar dicho umbral como mayor a 10 unidades. Sin embargo varios autores también consideran el valor de 5 como dicho umbral. Nosotros en el curso usaremos el valor de 10, salvo que se diga lo contrario.\n",
    "\n",
    "La diferencia de usar por ejemplo la matriz de correlación para identificar la dependencia entre variables independientes, es que esta relaciones son por parejas solamente y el índice $VIF$ puede encintrar dependencias con grupos de más de 2 variables independientes.\n",
    "\n",
    "En resumen, la manera de proceder para la detección de la multicolinealidad es calcular dicho índice para todos los factores de entrada y eliminar el de mayor magnitud arriba de 10, en caso de existir. Posteriormente se vuelve a calcular dicho índice para todos los factores restantes y nuevamente se eimina el de mayor magnitud arriba de 10. Y así se procede hasta que todos los índices $VIF$ de los factores que quedan sean menores a 10.\n",
    "\n",
    "Existen varias librerías que calculan dicho índice $VIF$, nosotros nos apoyaremos en la librería \"statsmodels\", cuyo método variance_inflation_factor$(X,k)$ nos devuelve el índice $VIF_k$ del factor $k$ con respecto al resto de los factores de un conjunto de factores de entrada $X$. \n",
    "\n",
    "### Por cierto, toma en cuenta que esta técnica aplica solamente a factores de tipo numérico.\n",
    "\n",
    "Puedes consultar más al respecto en la documentación correspondiente:\n",
    "\n",
    "https://www.statsmodels.org/stable/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html\n",
    "\n",
    "Veámoslo con el mismo ejemplo que teníamos previamente, en el cual se generó un modelo lineal de 12 factores de entrada, de los solo la mitad, 6, son los independientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8edf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definamos una función para estar evaluando el índice VIF:\n",
    "\n",
    "\n",
    "def indice_vif(X):\n",
    "    \n",
    "    X = pd.DataFrame(X)  # nos aseguramos que las variable de entrada están en un DataFrame de Pandas.\n",
    "    vif = pd.DataFrame()   # inicializamos el DataFRame de vif\n",
    "    vif[\"factores\"] = X.columns   # recuperamos todos los factores de nuestro conjunto de entrada\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]  # FOR sobre las columnas/factores de X.\n",
    "\n",
    "    return(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310b4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['x1'] = [-3, 2, 3, 4, 5]\n",
    "df['x2'] = [9, 4, 9, 16, 25]\n",
    "df['x1+x2'] = [6.1, 4.2, 12.3, 19.8, 29.4]\n",
    "df['otro'] =[1,1,0,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec7d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_vif(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b07a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df.drop(['x1+x2'],axis=1)\n",
    "\n",
    "indice_vif(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0ada82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
